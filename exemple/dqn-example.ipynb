{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2269265-f070-4db3-8cc1-183f86692886",
   "metadata": {},
   "source": [
    "# Chess: DQN Learning Example\n",
    "\n",
    "- This is skeleton code of a DQN learning. You can change any code line to build your own agent.\n",
    "- TODO: Fill in the missing parts.\n",
    "  - `hyper-parameters`\n",
    "  - `create_q_model()`\n",
    "  - `convert_state(board)`\n",
    "  - `updated_q_values` (target Q value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d225b2b-9fc3-4577-bfc3-0899fb1f08a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [1] Prerequisite\n",
    "\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be000272-b287-41c7-b5ed-1bd352af1a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### TODO: Configuration paramaters for the whole setup\n",
    "gamma = 0.99      # Discount factor for past rewards\n",
    "epsilon = 1.0     # Epsilon greedy parameter\n",
    "epsilon_min = 0.1    # Minimum epsilon greedy parameter\n",
    "epsilon_max = 1.0     # Maximum epsilon greedy parameter\n",
    "epsilon_interval = epsilon_max - epsilon_min # Rate at which to reduce chance of random action being taken\n",
    "batch_size = 32    # Size of batch taken from replay buffer\n",
    "max_steps_per_episode = 10000\n",
    "max_episodes = 10000\n",
    "\n",
    "num_actions = 4096\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 1000000\n",
    "# Maximum replay length\n",
    "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
    "max_memory_length = 100000\n",
    "# Train the model after 4 actions\n",
    "update_after_actions = 4\n",
    "# How often to update the target network\n",
    "update_target_network = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a30512",
   "metadata": {},
   "source": [
    "### Open Gym Environment for Chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdb4550-1558-4ba7-a910-9faa34652511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('ml_chess_env:ChessGreedyEnv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31c434ec",
   "metadata": {},
   "source": [
    "### Build the Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85ef96c-cc48-426a-b2f3-12e002502bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_q_model():\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(64, ))\n",
    "\n",
    "    # \"Dense\" is the basic form of a neural network layer\n",
    "    # \"Dense\" stands for fully connected layer, which means each neuron in a layer\n",
    "    # receives input from all neurons of the previous layer.\n",
    "    layer1 = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Dense(128, activation=\"relu\")(layer1)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer2)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6ec4cd-dd1d-49cf-a50d-fb04628b0f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The first model makes the predictions for Q-values which are used to\n",
    "# make a action.\n",
    "model = create_q_model()\n",
    "# Build a target model for the prediction of future rewards.\n",
    "# The weights of a target model get updated every 10000 steps thus when the\n",
    "# loss between the Q-values is calculated the target Q-value is stable.\n",
    "model_target = create_q_model()\n",
    "# In the Deepmind paper they use RMSProp however then Adam optimizer\n",
    "# improves training time\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "# Using huber loss for stability\n",
    "loss_function = keras.losses.Huber()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f9cc39a",
   "metadata": {},
   "source": [
    "### Initialize Lists for Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218ba986-5c97-4166-afa9-cefcecc9564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for counting over episodes\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "# Experience replay buffers\n",
    "action_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "rewards_history = []\n",
    "done_history = []\n",
    "episode_reward_history = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5bcc3aa",
   "metadata": {},
   "source": [
    "### Transform From Observation of Environment To State for Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e272608d-9d0e-4c01-b32f-133815f66a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(board):\n",
    "    \"\"\"\n",
    "    Convert environment state(=board) into state tensor(=model input)\n",
    "    board : np.ndarray, shape=(64,)\n",
    "    \"\"\"\n",
    "    ### TODO: write your code ###\n",
    "    return np.array(board)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c204163d",
   "metadata": {},
   "source": [
    "### Epsilon-Soft Greedy Policy & Greedy Policy\n",
    "\n",
    "Note that <code>get_greedy_epsilon</code> is used for generating episodes in training steps for exploration and <code>get_greedy_action</code> is for get the best action when evaluating the resulting Q-network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1866419c-5bac-484e-b527-94b07c0087e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_greedy_epsilon(state, mask):\n",
    "    global epsilon\n",
    "    \n",
    "    # Use epsilon-greedy for exploration\n",
    "    if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "        # Take random action\n",
    "        #action = np.random.choice(num_actions)\n",
    "        action = np.random.choice([ i for i in range(num_actions) if mask[i] == 1 ])\n",
    "    else:\n",
    "        # Predict action Q-values\n",
    "        # From environment state\n",
    "        action_probs = model(np.expand_dims(state, 0), training=False)\n",
    "        \n",
    "        # select the action with maximum return with cells masked as 1\n",
    "        valid_probs = [ (i, action_probs[0][i]) for i in range(num_actions) if mask[i] == 1 ]\n",
    "        idx, val = max(valid_probs, key=lambda e: e[1])\n",
    "        action = np.random.choice([ i for i, prob in valid_probs if prob >= val ])\n",
    "    \n",
    "    # decay epsilon\n",
    "    epsilon -= epsilon_interval / epsilon_greedy_frames\n",
    "    epsilon = max(epsilon, epsilon_min)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e67c561-ffd1-4e28-977e-c285430e4d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_greedy_action(state, mask):\n",
    "    global epsilon\n",
    "    \n",
    "    # Predict action Q-values\n",
    "    # From environment state\n",
    "    action_probs = model(np.expand_dims(state, 0), training=False)\n",
    "    \n",
    "    valid_probs = [ (i, action_probs[0][i]) for i in range(num_actions) if mask[i] == 1 ]\n",
    "    idx, val = max(valid_probs, key=lambda e: e[1])\n",
    "    action = np.random.choice([ i for i, prob in valid_probs if prob >= val ])\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "972f7d65",
   "metadata": {},
   "source": [
    "### Sample A Batch from Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cece0b-2d15-4061-afc5-e94b8cabf7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_batch(batch_size):\n",
    "    # Get indices of samples for replay buffers\n",
    "    indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "\n",
    "    # Using list comprehension to sample from replay buffer\n",
    "    state_sample = np.array([state_history[i] for i in indices])\n",
    "    state_next_sample = np.array([state_next_history[i] for i in indices])\n",
    "    rewards_sample = [rewards_history[i] for i in indices]\n",
    "    action_sample = [action_history[i] for i in indices]\n",
    "    done_sample = tf.convert_to_tensor(\n",
    "        [float(done_history[i]) for i in indices]\n",
    "    )\n",
    "    \n",
    "    return state_sample, state_next_sample, rewards_sample, action_sample, done_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ed4dcc-f24e-4990-879a-c2f6af51a063",
   "metadata": {},
   "source": [
    "## [2] DQN Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343adc5c-37d7-4429-890e-b720a291548c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# episode = 10: avg. reward = 426.1\n",
      "# episode = 20: avg. reward = 627.25\n",
      "# episode = 30: avg. reward = 595.1333333333333\n",
      "# episode = 40: avg. reward = 528.325\n",
      "# episode = 50: avg. reward = 508.78\n",
      "# episode = 60: avg. reward = 512.5833333333334\n",
      "# episode = 70: avg. reward = 486.0285714285714\n",
      "# episode = 80: avg. reward = 516.65\n",
      "model sync - running reward: 541.15 at episode 86, frame count 10000\n",
      "# episode = 90: avg. reward = 529.5\n",
      "# episode = 100: avg. reward = 479.4\n",
      "# episode = 110: avg. reward = 459.48\n",
      "# episode = 120: avg. reward = 409.71\n",
      "# episode = 130: avg. reward = 439.71\n",
      "# episode = 140: avg. reward = 469.81\n",
      "# episode = 150: avg. reward = 489.42\n",
      "# episode = 160: avg. reward = 509.41\n",
      "# episode = 170: avg. reward = 508.96\n",
      "model sync - running reward: 488.85 at episode 177, frame count 20000\n",
      "# episode = 180: avg. reward = 488.76\n",
      "# episode = 190: avg. reward = 459.01\n",
      "# episode = 200: avg. reward = 509.5\n",
      "# episode = 210: avg. reward = 519.88\n",
      "# episode = 220: avg. reward = 549.32\n",
      "# episode = 230: avg. reward = 488.86\n",
      "# episode = 240: avg. reward = 458.99\n",
      "# episode = 250: avg. reward = 399.18\n",
      "# episode = 260: avg. reward = 379.14\n",
      "model sync - running reward: 368.90 at episode 263, frame count 30000\n",
      "# episode = 270: avg. reward = 349.19\n",
      "# episode = 280: avg. reward = 319.56\n",
      "# episode = 290: avg. reward = 349.21\n",
      "# episode = 300: avg. reward = 369.37\n",
      "# episode = 310: avg. reward = 358.58\n",
      "# episode = 320: avg. reward = 298.77\n",
      "# episode = 330: avg. reward = 319.29\n",
      "# episode = 340: avg. reward = 348.91\n",
      "# episode = 350: avg. reward = 378.44\n",
      "model sync - running reward: 357.95 at episode 356, frame count 40000\n",
      "# episode = 360: avg. reward = 357.87\n",
      "# episode = 370: avg. reward = 438.84\n",
      "# episode = 380: avg. reward = 438.22\n",
      "# episode = 390: avg. reward = 388.03\n",
      "# episode = 400: avg. reward = 326.55\n",
      "# episode = 410: avg. reward = 327.33\n",
      "# episode = 420: avg. reward = 367.64\n",
      "# episode = 430: avg. reward = 397.39\n",
      "# episode = 440: avg. reward = 377.45\n",
      "model sync - running reward: 387.72 at episode 445, frame count 50000\n",
      "# episode = 450: avg. reward = 408.57\n",
      "# episode = 460: avg. reward = 408.62\n",
      "# episode = 470: avg. reward = 418.04\n",
      "# episode = 480: avg. reward = 438.43\n",
      "# episode = 490: avg. reward = 468.22\n",
      "# episode = 500: avg. reward = 448.91\n",
      "# episode = 510: avg. reward = 458.72\n",
      "# episode = 520: avg. reward = 458.39\n",
      "# episode = 530: avg. reward = 428.43\n",
      "# episode = 540: avg. reward = 388.1\n",
      "model sync - running reward: 347.37 at episode 543, frame count 60000\n",
      "# episode = 550: avg. reward = 356.89\n",
      "# episode = 560: avg. reward = 377.09\n",
      "# episode = 570: avg. reward = 337.5\n",
      "# episode = 580: avg. reward = 336.92\n",
      "# episode = 590: avg. reward = 276.75\n",
      "# episode = 600: avg. reward = 327.75\n",
      "# episode = 610: avg. reward = 347.62\n",
      "# episode = 620: avg. reward = 338.15\n",
      "# episode = 630: avg. reward = 328.26\n",
      "model sync - running reward: 359.54 at episode 635, frame count 70000\n",
      "# episode = 640: avg. reward = 359.49\n",
      "# episode = 650: avg. reward = 379.99\n",
      "# episode = 660: avg. reward = 419.87\n",
      "# episode = 670: avg. reward = 399.59\n",
      "# episode = 680: avg. reward = 389.58\n",
      "# episode = 690: avg. reward = 450.16\n",
      "# episode = 700: avg. reward = 469.22\n",
      "# episode = 710: avg. reward = 449.45\n",
      "# episode = 720: avg. reward = 448.94\n",
      "model sync - running reward: 479.31 at episode 728, frame count 80000\n",
      "# episode = 730: avg. reward = 489.27\n",
      "# episode = 740: avg. reward = 478.26\n",
      "# episode = 750: avg. reward = 508.23\n",
      "# episode = 760: avg. reward = 488.83\n",
      "# episode = 770: avg. reward = 518.99\n",
      "# episode = 780: avg. reward = 519.41\n",
      "# episode = 790: avg. reward = 518.93\n",
      "# episode = 800: avg. reward = 479.16\n",
      "# episode = 810: avg. reward = 468.45\n",
      "# episode = 820: avg. reward = 498.24\n",
      "model sync - running reward: 477.75 at episode 824, frame count 90000\n",
      "# episode = 830: avg. reward = 407.17\n",
      "# episode = 840: avg. reward = 428.03\n",
      "# episode = 850: avg. reward = 417.84\n",
      "# episode = 860: avg. reward = 407.03\n",
      "# episode = 870: avg. reward = 346.22\n",
      "# episode = 880: avg. reward = 325.75\n",
      "# episode = 890: avg. reward = 366.38\n",
      "# episode = 900: avg. reward = 406.86\n",
      "# episode = 910: avg. reward = 397.37\n",
      "# episode = 920: avg. reward = 377.41\n",
      "model sync - running reward: 397.52 at episode 921, frame count 100000\n",
      "# episode = 930: avg. reward = 427.67\n",
      "# episode = 940: avg. reward = 477.14\n",
      "# episode = 950: avg. reward = 437.46\n",
      "# episode = 960: avg. reward = 407.94\n",
      "# episode = 970: avg. reward = 458.79\n",
      "# episode = 980: avg. reward = 488.85\n",
      "# episode = 990: avg. reward = 418.44\n",
      "# episode = 1000: avg. reward = 407.99\n",
      "model sync - running reward: 417.83 at episode 1002, frame count 110000\n",
      "# episode = 1010: avg. reward = 448.19\n",
      "# episode = 1020: avg. reward = 448.8\n",
      "# episode = 1030: avg. reward = 469.31\n",
      "# episode = 1040: avg. reward = 379.04\n",
      "# episode = 1050: avg. reward = 389.45\n",
      "# episode = 1060: avg. reward = 390.07\n",
      "# episode = 1070: avg. reward = 410.49\n",
      "# episode = 1080: avg. reward = 411.06\n",
      "# episode = 1090: avg. reward = 461.31\n",
      "model sync - running reward: 471.25 at episode 1091, frame count 120000\n",
      "# episode = 1100: avg. reward = 441.54\n",
      "# episode = 1110: avg. reward = 431.61\n",
      "# episode = 1120: avg. reward = 431.1\n",
      "# episode = 1130: avg. reward = 401.03\n",
      "# episode = 1140: avg. reward = 451.25\n",
      "# episode = 1150: avg. reward = 451.1\n",
      "# episode = 1160: avg. reward = 480.06\n",
      "# episode = 1170: avg. reward = 469.21\n",
      "# episode = 1180: avg. reward = 499.22\n",
      "model sync - running reward: 499.55 at episode 1182, frame count 130000\n",
      "# episode = 1190: avg. reward = 498.42\n",
      "# episode = 1200: avg. reward = 517.91\n",
      "# episode = 1210: avg. reward = 497.31\n",
      "# episode = 1220: avg. reward = 507.42\n",
      "# episode = 1230: avg. reward = 546.75\n",
      "# episode = 1240: avg. reward = 577.19\n",
      "# episode = 1250: avg. reward = 577.0\n",
      "# episode = 1260: avg. reward = 586.24\n",
      "# episode = 1270: avg. reward = 536.21\n",
      "model sync - running reward: 535.84 at episode 1277, frame count 140000\n",
      "# episode = 1280: avg. reward = 495.83\n",
      "# episode = 1290: avg. reward = 455.76\n",
      "# episode = 1300: avg. reward = 455.94\n",
      "# episode = 1310: avg. reward = 456.1\n",
      "# episode = 1320: avg. reward = 446.01\n",
      "# episode = 1330: avg. reward = 406.12\n",
      "# episode = 1340: avg. reward = 376.13\n",
      "# episode = 1350: avg. reward = 355.59\n",
      "# episode = 1360: avg. reward = 286.55\n",
      "# episode = 1370: avg. reward = 356.77\n",
      "model sync - running reward: 337.20 at episode 1375, frame count 150000\n",
      "# episode = 1380: avg. reward = 377.38\n",
      "# episode = 1390: avg. reward = 367.68\n",
      "# episode = 1400: avg. reward = 327.12\n",
      "# episode = 1410: avg. reward = 296.74\n",
      "# episode = 1420: avg. reward = 337.27\n",
      "# episode = 1430: avg. reward = 348.17\n",
      "# episode = 1440: avg. reward = 327.63\n",
      "# episode = 1450: avg. reward = 347.75\n",
      "# episode = 1460: avg. reward = 388.47\n",
      "model sync - running reward: 358.29 at episode 1464, frame count 160000\n",
      "# episode = 1470: avg. reward = 358.53\n",
      "# episode = 1480: avg. reward = 408.54\n",
      "# episode = 1490: avg. reward = 478.39\n",
      "# episode = 1500: avg. reward = 478.3\n",
      "# episode = 1510: avg. reward = 497.87\n",
      "# episode = 1520: avg. reward = 457.07\n",
      "# episode = 1530: avg. reward = 486.75\n",
      "# episode = 1540: avg. reward = 516.25\n",
      "# episode = 1550: avg. reward = 505.95\n",
      "# episode = 1560: avg. reward = 515.62\n",
      "model sync - running reward: 515.34 at episode 1565, frame count 170000\n",
      "# episode = 1570: avg. reward = 525.67\n",
      "# episode = 1580: avg. reward = 485.5\n",
      "# episode = 1590: avg. reward = 435.87\n",
      "# episode = 1600: avg. reward = 476.63\n",
      "# episode = 1610: avg. reward = 487.05\n",
      "# episode = 1620: avg. reward = 487.66\n",
      "# episode = 1630: avg. reward = 447.23\n",
      "# episode = 1640: avg. reward = 437.08\n",
      "# episode = 1650: avg. reward = 447.54\n",
      "model sync - running reward: 477.82 at episode 1656, frame count 180000\n",
      "# episode = 1660: avg. reward = 436.98\n",
      "# episode = 1670: avg. reward = 386.38\n",
      "# episode = 1680: avg. reward = 376.57\n",
      "# episode = 1690: avg. reward = 406.96\n",
      "# episode = 1700: avg. reward = 386.44\n",
      "# episode = 1710: avg. reward = 396.95\n",
      "# episode = 1720: avg. reward = 386.7\n",
      "# episode = 1730: avg. reward = 376.07\n",
      "# episode = 1740: avg. reward = 336.67\n",
      "# episode = 1750: avg. reward = 326.41\n",
      "model sync - running reward: 326.68 at episode 1752, frame count 190000\n",
      "# episode = 1760: avg. reward = 347.3\n",
      "# episode = 1770: avg. reward = 358.35\n",
      "# episode = 1780: avg. reward = 317.76\n",
      "# episode = 1790: avg. reward = 297.75\n",
      "# episode = 1800: avg. reward = 308.37\n",
      "# episode = 1810: avg. reward = 308.69\n",
      "# episode = 1820: avg. reward = 329.2\n",
      "# episode = 1830: avg. reward = 370.4\n",
      "model sync - running reward: 380.34 at episode 1833, frame count 200000\n",
      "# episode = 1840: avg. reward = 350.38\n",
      "# episode = 1850: avg. reward = 340.99\n",
      "# episode = 1860: avg. reward = 300.39\n",
      "# episode = 1870: avg. reward = 330.05\n",
      "# episode = 1880: avg. reward = 359.51\n",
      "# episode = 1890: avg. reward = 369.51\n",
      "# episode = 1900: avg. reward = 329.76\n",
      "# episode = 1910: avg. reward = 318.57\n",
      "# episode = 1920: avg. reward = 308.13\n",
      "model sync - running reward: 317.96 at episode 1923, frame count 210000\n",
      "# episode = 1930: avg. reward = 318.02\n",
      "# episode = 1940: avg. reward = 378.39\n",
      "# episode = 1950: avg. reward = 418.59\n",
      "# episode = 1960: avg. reward = 428.57\n",
      "# episode = 1970: avg. reward = 387.82\n",
      "# episode = 1980: avg. reward = 388.25\n",
      "# episode = 1990: avg. reward = 398.25\n",
      "# episode = 2000: avg. reward = 468.36\n",
      "# episode = 2010: avg. reward = 498.96\n",
      "model sync - running reward: 528.91 at episode 2019, frame count 220000\n",
      "# episode = 2020: avg. reward = 528.76\n",
      "# episode = 2030: avg. reward = 468.61\n",
      "# episode = 2040: avg. reward = 468.79\n",
      "# episode = 2050: avg. reward = 448.55\n",
      "# episode = 2060: avg. reward = 448.73\n",
      "# episode = 2070: avg. reward = 439.48\n",
      "# episode = 2080: avg. reward = 440.03\n",
      "# episode = 2090: avg. reward = 410.77\n",
      "# episode = 2100: avg. reward = 390.46\n",
      "model sync - running reward: 400.72 at episode 2102, frame count 230000\n",
      "# episode = 2110: avg. reward = 370.92\n",
      "# episode = 2120: avg. reward = 381.67\n",
      "# episode = 2130: avg. reward = 432.2\n",
      "# episode = 2140: avg. reward = 442.42\n",
      "# episode = 2150: avg. reward = 421.91\n",
      "# episode = 2160: avg. reward = 421.82\n",
      "# episode = 2170: avg. reward = 431.39\n",
      "# episode = 2180: avg. reward = 400.93\n",
      "model sync - running reward: 389.82 at episode 2188, frame count 240000\n",
      "# episode = 2190: avg. reward = 420.17\n",
      "# episode = 2200: avg. reward = 389.01\n",
      "# episode = 2210: avg. reward = 378.68\n",
      "# episode = 2220: avg. reward = 349.2\n",
      "# episode = 2230: avg. reward = 318.48\n",
      "# episode = 2240: avg. reward = 308.61\n",
      "# episode = 2250: avg. reward = 349.25\n",
      "# episode = 2260: avg. reward = 308.57\n",
      "# episode = 2270: avg. reward = 308.43\n",
      "# episode = 2280: avg. reward = 348.79\n",
      "model sync - running reward: 348.84 at episode 2282, frame count 250000\n",
      "# episode = 2290: avg. reward = 348.89\n",
      "# episode = 2300: avg. reward = 379.62\n",
      "# episode = 2310: avg. reward = 379.96\n",
      "# episode = 2320: avg. reward = 378.46\n",
      "# episode = 2330: avg. reward = 379.05\n",
      "# episode = 2340: avg. reward = 327.38\n",
      "# episode = 2350: avg. reward = 277.18\n",
      "# episode = 2360: avg. reward = 308.14\n",
      "# episode = 2370: avg. reward = 318.9\n",
      "model sync - running reward: 278.18 at episode 2376, frame count 260000\n",
      "# episode = 2380: avg. reward = 298.38\n",
      "# episode = 2390: avg. reward = 288.39\n",
      "# episode = 2400: avg. reward = 299.16\n",
      "# episode = 2410: avg. reward = 329.68\n",
      "# episode = 2420: avg. reward = 349.75\n",
      "# episode = 2430: avg. reward = 389.76\n",
      "# episode = 2440: avg. reward = 461.25\n",
      "# episode = 2450: avg. reward = 471.52\n",
      "model sync - running reward: 471.71 at episode 2453, frame count 270000\n",
      "# episode = 2460: avg. reward = 451.33\n",
      "# episode = 2470: avg. reward = 500.7\n",
      "# episode = 2480: avg. reward = 500.75\n",
      "# episode = 2490: avg. reward = 509.88\n",
      "# episode = 2500: avg. reward = 469.06\n",
      "# episode = 2510: avg. reward = 468.03\n",
      "# episode = 2520: avg. reward = 428.33\n",
      "# episode = 2530: avg. reward = 418.27\n",
      "# episode = 2540: avg. reward = 398.19\n",
      "model sync - running reward: 428.17 at episode 2549, frame count 280000\n",
      "# episode = 2550: avg. reward = 428.24\n",
      "# episode = 2560: avg. reward = 498.67\n",
      "# episode = 2570: avg. reward = 478.81\n",
      "# episode = 2580: avg. reward = 478.04\n",
      "# episode = 2590: avg. reward = 458.68\n",
      "# episode = 2600: avg. reward = 509.63\n",
      "# episode = 2610: avg. reward = 500.92\n",
      "# episode = 2620: avg. reward = 492.08\n",
      "# episode = 2630: avg. reward = 522.28\n",
      "model sync - running reward: 532.33 at episode 2632, frame count 290000\n",
      "# episode = 2640: avg. reward = 511.8\n",
      "# episode = 2650: avg. reward = 511.86\n",
      "# episode = 2660: avg. reward = 541.73\n",
      "# episode = 2670: avg. reward = 521.71\n",
      "# episode = 2680: avg. reward = 583.02\n",
      "# episode = 2690: avg. reward = 613.33\n",
      "# episode = 2700: avg. reward = 572.4\n",
      "# episode = 2710: avg. reward = 571.87\n",
      "model sync - running reward: 590.94 at episode 2717, frame count 300000\n",
      "# episode = 2720: avg. reward = 600.62\n",
      "# episode = 2730: avg. reward = 489.34\n",
      "# episode = 2740: avg. reward = 509.33\n",
      "# episode = 2750: avg. reward = 468.98\n",
      "# episode = 2760: avg. reward = 408.27\n",
      "# episode = 2770: avg. reward = 468.67\n",
      "# episode = 2780: avg. reward = 368.97\n",
      "# episode = 2790: avg. reward = 359.06\n",
      "# episode = 2800: avg. reward = 388.92\n",
      "model sync - running reward: 439.13 at episode 2807, frame count 310000\n",
      "# episode = 2810: avg. reward = 419.27\n",
      "# episode = 2820: avg. reward = 409.08\n",
      "# episode = 2830: avg. reward = 490.27\n",
      "# episode = 2840: avg. reward = 470.55\n",
      "# episode = 2850: avg. reward = 521.74\n",
      "# episode = 2860: avg. reward = 512.17\n",
      "# episode = 2870: avg. reward = 402.21\n",
      "# episode = 2880: avg. reward = 380.97\n",
      "model sync - running reward: 351.31 at episode 2887, frame count 320000\n",
      "# episode = 2890: avg. reward = 361.47\n",
      "# episode = 2900: avg. reward = 281.08\n",
      "# episode = 2910: avg. reward = 240.83\n",
      "# episode = 2920: avg. reward = 292.16\n",
      "# episode = 2930: avg. reward = 271.83\n",
      "# episode = 2940: avg. reward = 261.39\n",
      "# episode = 2950: avg. reward = 240.13\n",
      "# episode = 2960: avg. reward = 240.43\n",
      "model sync - running reward: 301.00 at episode 2965, frame count 330000\n",
      "# episode = 2970: avg. reward = 321.46\n",
      "# episode = 2980: avg. reward = 392.28\n",
      "# episode = 2990: avg. reward = 371.49\n",
      "# episode = 3000: avg. reward = 442.63\n",
      "# episode = 3010: avg. reward = 452.46\n",
      "# episode = 3020: avg. reward = 432.21\n",
      "# episode = 3030: avg. reward = 431.55\n",
      "# episode = 3040: avg. reward = 441.5\n",
      "model sync - running reward: 481.92 at episode 3047, frame count 340000\n",
      "# episode = 3050: avg. reward = 471.76\n",
      "# episode = 3060: avg. reward = 491.96\n",
      "# episode = 3070: avg. reward = 511.23\n",
      "# episode = 3080: avg. reward = 511.21\n",
      "# episode = 3090: avg. reward = 470.9\n",
      "# episode = 3100: avg. reward = 430.93\n",
      "# episode = 3110: avg. reward = 450.96\n",
      "# episode = 3120: avg. reward = 440.56\n",
      "model sync - running reward: 430.87 at episode 3122, frame count 350000\n",
      "# episode = 3130: avg. reward = 420.87\n",
      "# episode = 3140: avg. reward = 411.33\n",
      "# episode = 3150: avg. reward = 361.09\n",
      "# episode = 3160: avg. reward = 360.61\n",
      "# episode = 3170: avg. reward = 350.28\n",
      "# episode = 3180: avg. reward = 320.23\n",
      "# episode = 3190: avg. reward = 380.78\n",
      "# episode = 3200: avg. reward = 410.66\n",
      "model sync - running reward: 400.79 at episode 3202, frame count 360000\n",
      "# episode = 3210: avg. reward = 400.68\n",
      "# episode = 3220: avg. reward = 400.91\n",
      "# episode = 3230: avg. reward = 441.13\n",
      "# episode = 3240: avg. reward = 409.96\n",
      "# episode = 3250: avg. reward = 420.28\n",
      "# episode = 3260: avg. reward = 390.43\n",
      "# episode = 3270: avg. reward = 330.62\n",
      "# episode = 3280: avg. reward = 370.23\n",
      "# episode = 3290: avg. reward = 360.06\n",
      "model sync - running reward: 360.06 at episode 3290, frame count 370000\n",
      "# episode = 3300: avg. reward = 279.02\n",
      "# episode = 3310: avg. reward = 258.47\n",
      "# episode = 3320: avg. reward = 198.03\n",
      "# episode = 3330: avg. reward = 168.58\n",
      "# episode = 3340: avg. reward = 210.22\n",
      "# episode = 3350: avg. reward = 209.38\n",
      "# episode = 3360: avg. reward = 249.95\n",
      "# episode = 3370: avg. reward = 279.86\n",
      "model sync - running reward: 259.65 at episode 3371, frame count 380000\n",
      "# episode = 3380: avg. reward = 270.23\n",
      "# episode = 3390: avg. reward = 299.81\n",
      "# episode = 3400: avg. reward = 370.88\n",
      "# episode = 3410: avg. reward = 391.25\n",
      "# episode = 3420: avg. reward = 442.04\n",
      "# episode = 3430: avg. reward = 492.15\n",
      "# episode = 3440: avg. reward = 481.66\n",
      "# episode = 3450: avg. reward = 502.54\n",
      "model sync - running reward: 512.62 at episode 3451, frame count 390000\n",
      "# episode = 3460: avg. reward = 452.08\n",
      "# episode = 3470: avg. reward = 442.01\n",
      "# episode = 3480: avg. reward = 412.65\n",
      "# episode = 3490: avg. reward = 403.7\n",
      "# episode = 3500: avg. reward = 434.06\n",
      "# episode = 3510: avg. reward = 373.8\n",
      "# episode = 3520: avg. reward = 352.41\n",
      "# episode = 3530: avg. reward = 331.73\n",
      "model sync - running reward: 311.21 at episode 3532, frame count 400000\n",
      "# episode = 3540: avg. reward = 340.89\n",
      "# episode = 3550: avg. reward = 380.7\n",
      "# episode = 3560: avg. reward = 420.7\n",
      "# episode = 3570: avg. reward = 380.17\n",
      "# episode = 3580: avg. reward = 409.61\n",
      "# episode = 3590: avg. reward = 398.9\n",
      "# episode = 3600: avg. reward = 388.38\n",
      "# episode = 3610: avg. reward = 438.55\n",
      "model sync - running reward: 448.36 at episode 3615, frame count 410000\n",
      "# episode = 3620: avg. reward = 439.43\n",
      "# episode = 3630: avg. reward = 430.43\n",
      "# episode = 3640: avg. reward = 390.6\n",
      "# episode = 3650: avg. reward = 300.93\n",
      "# episode = 3660: avg. reward = 260.54\n",
      "# episode = 3670: avg. reward = 280.97\n",
      "# episode = 3680: avg. reward = 251.2\n",
      "# episode = 3690: avg. reward = 271.53\n",
      "model sync - running reward: 271.84 at episode 3696, frame count 420000\n",
      "# episode = 3700: avg. reward = 251.66\n",
      "# episode = 3710: avg. reward = 200.94\n",
      "# episode = 3720: avg. reward = 200.71\n",
      "# episode = 3730: avg. reward = 169.77\n",
      "# episode = 3740: avg. reward = 190.3\n",
      "# episode = 3750: avg. reward = 259.4\n",
      "# episode = 3760: avg. reward = 290.42\n",
      "# episode = 3770: avg. reward = 330.57\n",
      "# episode = 3780: avg. reward = 340.26\n",
      "model sync - running reward: 340.01 at episode 3782, frame count 430000\n",
      "# episode = 3790: avg. reward = 330.22\n",
      "# episode = 3800: avg. reward = 309.7\n",
      "# episode = 3810: avg. reward = 360.39\n",
      "# episode = 3820: avg. reward = 349.68\n",
      "# episode = 3830: avg. reward = 389.63\n",
      "# episode = 3840: avg. reward = 429.51\n",
      "# episode = 3850: avg. reward = 400.02\n",
      "# episode = 3860: avg. reward = 338.7\n",
      "model sync - running reward: 329.01 at episode 3864, frame count 440000\n",
      "# episode = 3870: avg. reward = 319.07\n",
      "# episode = 3880: avg. reward = 349.37\n",
      "# episode = 3890: avg. reward = 369.17\n",
      "# episode = 3900: avg. reward = 388.29\n",
      "# episode = 3910: avg. reward = 387.85\n",
      "# episode = 3920: avg. reward = 388.92\n",
      "# episode = 3930: avg. reward = 379.37\n",
      "# episode = 3940: avg. reward = 360.44\n",
      "model sync - running reward: 370.19 at episode 3947, frame count 450000\n",
      "# episode = 3950: avg. reward = 340.03\n",
      "# episode = 3960: avg. reward = 359.78\n",
      "# episode = 3970: avg. reward = 359.26\n",
      "# episode = 3980: avg. reward = 349.09\n",
      "# episode = 3990: avg. reward = 338.72\n",
      "# episode = 4000: avg. reward = 350.2\n",
      "# episode = 4010: avg. reward = 320.64\n",
      "# episode = 4020: avg. reward = 330.15\n",
      "# episode = 4030: avg. reward = 320.64\n",
      "model sync - running reward: 320.64 at episode 4030, frame count 460000\n",
      "# episode = 4040: avg. reward = 300.05\n",
      "# episode = 4050: avg. reward = 259.55\n",
      "# episode = 4060: avg. reward = 279.98\n",
      "# episode = 4070: avg. reward = 320.11\n",
      "# episode = 4080: avg. reward = 300.63\n",
      "# episode = 4090: avg. reward = 280.98\n",
      "# episode = 4100: avg. reward = 300.95\n",
      "# episode = 4110: avg. reward = 351.27\n",
      "model sync - running reward: 361.08 at episode 4118, frame count 470000\n",
      "# episode = 4120: avg. reward = 351.5\n",
      "# episode = 4130: avg. reward = 370.97\n",
      "# episode = 4140: avg. reward = 411.21\n",
      "# episode = 4150: avg. reward = 452.23\n",
      "# episode = 4160: avg. reward = 452.86\n",
      "# episode = 4170: avg. reward = 402.34\n",
      "# episode = 4180: avg. reward = 401.8\n",
      "# episode = 4190: avg. reward = 371.64\n",
      "model sync - running reward: 371.89 at episode 4193, frame count 480000\n",
      "# episode = 4200: avg. reward = 381.44\n",
      "# episode = 4210: avg. reward = 371.44\n",
      "# episode = 4220: avg. reward = 381.23\n",
      "# episode = 4230: avg. reward = 360.99\n",
      "# episode = 4240: avg. reward = 370.77\n",
      "# episode = 4250: avg. reward = 391.41\n",
      "# episode = 4260: avg. reward = 391.98\n",
      "# episode = 4270: avg. reward = 402.6\n",
      "model sync - running reward: 442.27 at episode 4275, frame count 490000\n",
      "# episode = 4280: avg. reward = 432.39\n",
      "# episode = 4290: avg. reward = 482.88\n",
      "# episode = 4300: avg. reward = 432.8\n",
      "# episode = 4310: avg. reward = 372.2\n",
      "# episode = 4320: avg. reward = 381.9\n",
      "# episode = 4330: avg. reward = 392.11\n",
      "# episode = 4340: avg. reward = 362.18\n",
      "# episode = 4350: avg. reward = 371.55\n",
      "model sync - running reward: 411.05 at episode 4358, frame count 500000\n",
      "# episode = 4360: avg. reward = 420.91\n",
      "# episode = 4370: avg. reward = 410.9\n",
      "# episode = 4380: avg. reward = 411.44\n",
      "# episode = 4390: avg. reward = 400.77\n",
      "# episode = 4400: avg. reward = 440.82\n",
      "# episode = 4410: avg. reward = 481.74\n",
      "# episode = 4420: avg. reward = 502.82\n",
      "# episode = 4430: avg. reward = 472.81\n",
      "model sync - running reward: 472.71 at episode 4431, frame count 510000\n",
      "# episode = 4440: avg. reward = 452.4\n",
      "# episode = 4450: avg. reward = 412.29\n",
      "# episode = 4460: avg. reward = 362.2\n",
      "# episode = 4470: avg. reward = 392.74\n",
      "# episode = 4480: avg. reward = 423.14\n",
      "# episode = 4490: avg. reward = 403.24\n",
      "# episode = 4500: avg. reward = 353.48\n",
      "model sync - running reward: 333.13 at episode 4504, frame count 520000\n",
      "# episode = 4510: avg. reward = 332.79\n",
      "# episode = 4520: avg. reward = 261.84\n",
      "# episode = 4530: avg. reward = 252.22\n",
      "# episode = 4540: avg. reward = 302.03\n",
      "# episode = 4550: avg. reward = 302.06\n",
      "# episode = 4560: avg. reward = 321.53\n",
      "# episode = 4570: avg. reward = 291.02\n",
      "# episode = 4580: avg. reward = 240.71\n",
      "model sync - running reward: 230.37 at episode 4583, frame count 530000\n",
      "# episode = 4590: avg. reward = 240.56\n",
      "# episode = 4600: avg. reward = 229.79\n",
      "# episode = 4610: avg. reward = 249.06\n",
      "# episode = 4620: avg. reward = 309.95\n",
      "# episode = 4630: avg. reward = 339.38\n",
      "# episode = 4640: avg. reward = 299.97\n",
      "# episode = 4650: avg. reward = 320.12\n",
      "# episode = 4660: avg. reward = 300.79\n",
      "model sync - running reward: 290.87 at episode 4664, frame count 540000\n",
      "# episode = 4670: avg. reward = 290.85\n",
      "# episode = 4680: avg. reward = 300.32\n",
      "# episode = 4690: avg. reward = 310.25\n",
      "# episode = 4700: avg. reward = 360.6\n",
      "# episode = 4710: avg. reward = 361.37\n",
      "# episode = 4720: avg. reward = 370.95\n",
      "# episode = 4730: avg. reward = 361.73\n",
      "model sync - running reward: 351.59 at episode 4737, frame count 550000\n",
      "# episode = 4740: avg. reward = 361.77\n",
      "# episode = 4750: avg. reward = 372.11\n",
      "# episode = 4760: avg. reward = 392.48\n",
      "# episode = 4770: avg. reward = 422.46\n",
      "# episode = 4780: avg. reward = 413.21\n",
      "# episode = 4790: avg. reward = 403.66\n",
      "# episode = 4800: avg. reward = 363.68\n",
      "model sync - running reward: 353.49 at episode 4802, frame count 560000\n",
      "# episode = 4810: avg. reward = 373.63\n",
      "# episode = 4820: avg. reward = 323.59\n",
      "# episode = 4830: avg. reward = 312.42\n",
      "# episode = 4840: avg. reward = 312.1\n",
      "# episode = 4850: avg. reward = 280.99\n",
      "# episode = 4860: avg. reward = 260.14\n",
      "# episode = 4870: avg. reward = 269.55\n",
      "# episode = 4880: avg. reward = 238.72\n",
      "model sync - running reward: 228.77 at episode 4882, frame count 570000\n",
      "# episode = 4890: avg. reward = 269.15\n",
      "# episode = 4900: avg. reward = 269.2\n",
      "# episode = 4910: avg. reward = 219.54\n",
      "# episode = 4920: avg. reward = 229.64\n",
      "# episode = 4930: avg. reward = 239.88\n",
      "# episode = 4940: avg. reward = 240.44\n",
      "# episode = 4950: avg. reward = 240.93\n",
      "model sync - running reward: 240.93 at episode 4950, frame count 580000\n",
      "# episode = 4960: avg. reward = 291.52\n",
      "# episode = 4970: avg. reward = 312.28\n",
      "# episode = 4980: avg. reward = 302.48\n",
      "# episode = 4990: avg. reward = 241.0\n",
      "# episode = 5000: avg. reward = 281.79\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: model.5000\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: target_model.5000\\assets\n",
      "# episode = 5010: avg. reward = 322.15\n",
      "# episode = 5020: avg. reward = 291.59\n",
      "model sync - running reward: 291.70 at episode 5025, frame count 590000\n",
      "# episode = 5030: avg. reward = 302.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_38944/3481507337.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[1;31m# Use epsilon-greedy for exploration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0maction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_greedy_epsilon\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maction_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[1;31m# Apply the sampled action in our environment\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_38944/2579734794.py\u001B[0m in \u001B[0;36mget_greedy_epsilon\u001B[1;34m(state, mask)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;31m# select the action with maximum return with cells masked as 1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mvalid_probs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maction_probs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_actions\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalid_probs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[0maction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprob\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mvalid_probs\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mprob\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mval\u001B[0m \u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__bool__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1058\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1059\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__bool__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1060\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1061\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1062\u001B[0m   \u001B[0m__nonzero__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m__bool__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1113\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1114\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1115\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1116\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1117\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(max_episodes):  # Run until solved\n",
    "    board, info = env.reset()\n",
    "    state = convert_state(board)\n",
    "    action_mask = info['action_mask']\n",
    "    episode_reward = 0\n",
    "\n",
    "    for timestep in range(1, max_steps_per_episode):\n",
    "        # env.render(); Adding this line would show the attempts\n",
    "        # of the agent in a pop up window.\n",
    "        frame_count += 1\n",
    "\n",
    "        # Use epsilon-greedy for exploration\n",
    "        action = get_greedy_epsilon(state, action_mask)\n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        board, reward, done, _, info = env.step(action)\n",
    "        state_next = convert_state(board)\n",
    "        action_mask = info['action_mask']\n",
    "\n",
    "        # cummulate reward of the episode\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Save actions and states in replay buffer\n",
    "        action_history.append(action)\n",
    "        state_history.append(state)\n",
    "        state_next_history.append(state_next)\n",
    "        done_history.append(done)\n",
    "        rewards_history.append(reward)\n",
    "        state = state_next\n",
    "\n",
    "        # Update every fourth frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
    "\n",
    "            # Sample a batch from replay buffer\n",
    "            state_sample, state_next_sample, rewards_sample, action_sample, done_sample = \\\n",
    "                sample_batch(batch_size)\n",
    "\n",
    "            future_rewards = model_target.predict(state_next_sample, verbose=0)\n",
    "            \n",
    "            # Q value = reward + discount factor * maximum future reward\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(future_rewards, axis=1)  ### TODO: write your code ###\n",
    "\n",
    "            # Create a mask so we only calculate loss on the updated Q-values\n",
    "            masks = tf.one_hot(action_sample, num_actions)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Train the model on the states and updated Q-values\n",
    "                q_values = model(state_sample)\n",
    "\n",
    "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                \n",
    "                # Calculate loss between new Q-value and old Q-value\n",
    "                loss = loss_function(updated_q_values, q_action)\n",
    "\n",
    "            # Backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # Periodically, update the the target network with new weights\n",
    "            model_target.set_weights(model.get_weights())\n",
    "            # Log details\n",
    "            template = \"model sync - running reward: {:.2f} at episode {}, frame count {}\"\n",
    "            print(template.format(running_reward, episode_count, frame_count))\n",
    "\n",
    "        # Limit the state and reward history\n",
    "        if len(rewards_history) > max_memory_length:\n",
    "            del rewards_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del action_history[:1]\n",
    "            del done_history[:1]\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update running reward to check condition for solving\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    if len(episode_reward_history) > 100:\n",
    "        del episode_reward_history[:1]\n",
    "    running_reward = np.mean(episode_reward_history)\n",
    "\n",
    "    episode_count += 1\n",
    "    \n",
    "    if episode_count % 10 == 0:\n",
    "        print(\"# episode = {}: avg. reward = {}\".format(episode_count, running_reward))\n",
    "\n",
    "    if episode_count % 5000 == 0:\n",
    "        model.save('model.{}'.format(episode_count))\n",
    "        model_target.save('target_model.{}'.format(episode_count))\n",
    "\n",
    "model.save('model.final')\n",
    "model_target.save('target_model.final')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4984b880-e427-48cb-bf91-13a91d6529f5",
   "metadata": {},
   "source": [
    "## [3] Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e621d1-e41a-4dbf-99fa-8aee2f20106a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "861a4dc1-e997-4d7e-8174-5c2428cdc849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . . k . . . .\\n. . . . . . n p\\n. . P P . b . r\\n. . . . p b n Q\\np p . . P p . .\\n. . . P . P p P\\nP . . N . . P .\\n. R B . K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove g5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light lastmove e6\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 240)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 240)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 150)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 150)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(330, 150)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 105)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 105)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 105)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(150, 15)\" /></svg>'",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . . k . . . .\n. . . . . . n p\n. . P P . b . r\n. . . . p b n Q\np p . . P p . .\n. . . P . P p P\nP . . N . . P .\n. R B . K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove g5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light lastmove e6\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 240)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 240)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 150)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 150)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(330, 150)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 105)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 105)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 105)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(150, 15)\" /></svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "board, info = env.reset()\n",
    "done = False\n",
    "\n",
    "for timestep in range(1, 80):\n",
    "    state = convert_state(board)\n",
    "    action_mask = info['action_mask']\n",
    "    \n",
    "    move = get_greedy_action(state, action_mask)\n",
    "    board, reward, done, _, info = env.step(move)\n",
    "    \n",
    "    clear_output()\n",
    "    display(env.render())\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28121eac-8652-430c-9ddf-0d692c283c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'action_mask': array([False, False, False, ..., False, False, False]),\n 'material_value': 15,\n 'result': '*',\n 'termination': ''}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5602a-1a96-46b6-a62f-04637388dcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
